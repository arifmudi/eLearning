{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h1><strong>taudata Analytics</strong></h1></center>\n",
    "<center><h2><strong><font color=\"blue\">DL 02 - Pendahuluan PyTorch untuk Deep learning</font></strong></h2></center>\n",
    "<img alt=\"\" src=\"images/covers/taudata-cover.jpg\"/>\n",
    "\n",
    "<b><center>(C) Taufik Sutanto</center>\n",
    "<center><h3><font color=\"blue\">https://taudataid.github.io/dl02/</font></h3></center>\n",
    "<center><h3><font color=\"blue\">Video Penjelasan: </font></h3></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\"> Prasyarat Module </font></center>\n",
    "\n",
    "### Sebelum dilanjutkan, yakinkan sudah mempelajari dengan baik module:\n",
    "* https://taudataid.github.io/adsp01/\n",
    "* https://taudataid.github.io/adsp02/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\"> Instalasi </font></center>\n",
    "\n",
    "* Sangat mudah, ikuti perintah di https://pytorch.org/get-started/locally/\n",
    "* Perhatikan harware yang dimiliki.\n",
    "* Saat ini AMD (Rocm) sudah disupport oleh PyTorch dan TensorFlow\n",
    "* Perhatikan jika anda install PyTorch dan Tensorflow pada environment yang sama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Module\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Numpy and Pytorch versions = 1.21.5, 1.11.0+cu113\n",
      "Using device: cuda, NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Currently Memory Allocated, Cached = 0.0 GB,  0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# Kalau saya sukanya cek versi dan apakah PyTorch (atau tensorflow) sudah dapat mengakses GPU atau belum\n",
    "\n",
    "print(\"Using Numpy and Pytorch versions = {}, {}\".format(np.__version__, torch.__version__))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device, end=', ')\n",
    "if device.type == 'cuda': #Additional Info when using cuda\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Currently Memory Allocated, Cached =', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB, ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor dari Python List\n",
    "\n",
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 2]), 'torch.LongTensor')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape, x_data.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]], dtype=torch.int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor dari Numpy\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "x_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.8822, 0.1105],\n",
      "        [0.7793, 0.3140]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ukuran  & property (shape, datatype) sama, tapi element berbeda.\n",
    "#  unless explicitly overridden.\n",
    "\n",
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 2]), 'torch.LongTensor')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ones.shape, x_ones.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.0461, 0.0025, 0.3966],\n",
      "        [0.4182, 0.3375, 0.1969]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# dimensi Tensor adalah Tuple\n",
    "\n",
    "shape = (2, 3)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check Tensor ada dimana\n",
    "tensor = torch.rand(3, 4)\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device tensor is stored on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Bisa pindah ke GPU ... perhatikan kita bisa punya >1 GPU, index GPU mulai dari 0\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')\n",
    "    print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  0.,  1.,  1.],\n",
      "        [-2., -2., -2., -2.],\n",
      "        [ 1.,  0.,  1.,  1.],\n",
      "        [ 1.,  0.,  1., 99.]])\n"
     ]
    }
   ],
   "source": [
    "# Slicing Tensor = Numpy\n",
    "tensor = torch.ones(4, 4)\n",
    "tensor[:,1] = 0.0\n",
    "tensor[1,:] = -2.0\n",
    "tensor[-1,-1] = 99.0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.],\n",
      "        [-2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.],\n",
      "        [ 1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.],\n",
      "        [ 1.,  0.,  1., 99.,  1.,  0.,  1., 99.,  1.,  0.,  1., 99.]])\n"
     ]
    }
   ],
   "source": [
    "# Operasi Concatenasi (dan operasi lainnya) juga mirip dengan Numpy\n",
    "\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.mul(tensor) \n",
      " tensor([[1.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.0000e+00, 4.0000e+00, 4.0000e+00, 4.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00, 1.0000e+00, 9.8010e+03]]) \n",
      "\n",
      "tensor * tensor \n",
      " tensor([[1.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.0000e+00, 4.0000e+00, 4.0000e+00, 4.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00, 1.0000e+00, 9.8010e+03]])\n"
     ]
    }
   ],
   "source": [
    "# Operasi Tensor = Numpy, berarti element Wise ... Hati-hati tidak seperti Matlab.\n",
    "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
    "# Alternative syntax:\n",
    "print(f\"tensor * tensor \\n {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.matmul(tensor.T) \n",
      " tensor([[ 3.0000e+00, -6.0000e+00,  3.0000e+00,  1.0100e+02],\n",
      "        [-6.0000e+00,  1.6000e+01, -6.0000e+00, -2.0200e+02],\n",
      "        [ 3.0000e+00, -6.0000e+00,  3.0000e+00,  1.0100e+02],\n",
      "        [ 1.0100e+02, -2.0200e+02,  1.0100e+02,  9.8030e+03]]) \n",
      "\n",
      "tensor @ tensor.T \n",
      " tensor([[ 3.0000e+00, -6.0000e+00,  3.0000e+00,  1.0100e+02],\n",
      "        [-6.0000e+00,  1.6000e+01, -6.0000e+00, -2.0200e+02],\n",
      "        [ 3.0000e+00, -6.0000e+00,  3.0000e+00,  1.0100e+02],\n",
      "        [ 1.0100e+02, -2.0200e+02,  1.0100e+02,  9.8030e+03]])\n"
     ]
    }
   ],
   "source": [
    "# Perkalian Matrix\n",
    "\n",
    "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
    "# Alternative syntax:\n",
    "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  0.,  1.,  1.],\n",
      "        [-2., -2., -2., -2.],\n",
      "        [ 1.,  0.,  1.,  1.],\n",
      "        [ 1.,  0.,  1., 99.]]) \n",
      "\n",
      "tensor([[  6.,   5.,   6.,   6.],\n",
      "        [  3.,   3.,   3.,   3.],\n",
      "        [  6.,   5.,   6.,   6.],\n",
      "        [  6.,   5.,   6., 104.]])\n"
     ]
    }
   ],
   "source": [
    "# Tanda \"_\" artinya operasi \"inplace\" ... ini penting untuk diingat untuk menekan memory. Terutama di GPU\n",
    "\n",
    "print(tensor, \"\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Tentu saja Tensor dapat diubah kembali kke numpy\n",
    "# Coba sampaikan di kolom komentar, kira-kira kapan kita butuh hal ini?\n",
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# Tapi \"reference to variable\" seperti di adsp-01 tetap berlaku (pythonic)\n",
    "# perubahan di t akan merubah n\n",
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\"> Akhir Modul DL 02 - Pendahuluan PyTorch untuk Deep learning</font></center>\n",
    "\n",
    "* Referensi: https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py\n",
    "<hr />\n",
    "<img alt=\"\" src=\"images/meme-cartoon/meme tensors flow node to node.jpeg\" style=\"height: 400px;\"/>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
